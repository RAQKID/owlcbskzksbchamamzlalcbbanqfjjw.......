'use strict';

class Client {
  constructor(apiKey, dev = false, isBrowser = typeof window !== "undefined") {
    this.#isBrowser = isBrowser;
    this.host = `http${dev ? "://localhost:8080" : "s://api.bytez.com"}/models/v2/`;
    this.headers = {
      lang: "javascript",
      Authorization: `Key ${apiKey}`,
      "content-type": "application/json"
    };
    if (isBrowser === false) {
      import('stream').then((module) => {
        this.#Readable = module.Readable ?? module.default?.Readable;
      });
    }
  }
  #Readable;
  #isBrowser;
  fetch = fetch;
  host = "";
  headers = {};
  async request(path, method, body, providerKey) {
    try {
      const res = await this.fetch(this.host + path, {
        method,
        headers: providerKey === void 0 ? this.headers : { ...this.headers, ["provider-key"]: providerKey },
        body: body ? JSON.stringify(body) : void 0
      });
      if (method === "POST" && !res.ok && res.headers.get("content-type") !== "application/json") {
        throw new Error(res.statusText);
      }
      if (res.body !== null && (body?.stream === true || body?.json === false)) {
        return this.#isBrowser ? res.body : this.#Readable.fromWeb(res.body);
      } else {
        return res.json();
      }
    } catch (error) {
      return { error: error.message, output: null };
    }
  }
}

class Model {
  constructor(modelId, bytez, client, providerKey) {
    this.#client = client;
    this.id = modelId;
    this.#providerKey = providerKey;
    this.#ready = bytez.list.models({ modelId }).then((response) => {
      const mediaGenerators = /* @__PURE__ */ new Set([
        "text-to-audio",
        "text-to-image",
        "text-to-video",
        "text-to-speech"
      ]);
      this.details = response?.output?.[0] ?? {};
      this.#isGeneratingMedia = mediaGenerators.has(this.details.task);
    });
  }
  #client;
  #ready;
  #isGeneratingMedia = false;
  #providerKey;
  /** The modelId, for example `openai-community/gpt2` */
  id;
  /** Default model params */
  params;
  /** details about the model */
  details;
  /**
   * For open-source models, `create` an auto-scaling cluster to run this model
   *
   * @param options Cluster configuration
   */
  create = (options) => this.#client.request(this.id, "PUT", options);
  /** For open-source models, `read` your cluster */
  read = () => this.#client.request(this.id, "GET");
  /**
   * For open-source models, `update` your cluster
   *
   * @param options Cluster configuration
   */
  update = (options) => this.#client.request(this.id, "PATCH", options);
  /** For open-source models, `delete` your cluster */
  delete = () => this.#client.request(this.id, "DELETE");
  async run(input, params, stream) {
    const postBody = {
      params: typeof params === "boolean" || params === void 0 ? void 0 : params
    };
    await this.#ready;
    if (params === true || stream === true) {
      if (this.#isGeneratingMedia) {
        postBody.json = false;
      } else {
        postBody.stream = true;
      }
    }
    switch (this.details.task) {
      // require "text" as input
      case "sentence-similarity":
      case "fill-mask":
      case "text-to-speech":
      case "text-to-audio":
      case "text-to-image":
      case "translation":
      case "summarization":
      case "text-to-video":
      case "feature-extraction":
      case "text-classification":
      case "token-classification":
      case "text2text-generation":
      case "text-generation": {
        postBody["text"] = input;
        break;
      }
      //
      // require "messages" as input
      case "chat": {
        postBody["messages"] = input;
        break;
      }
      //
      // requires media as input ('image', 'audio',"video'?)
      //
      case "video-classification":
      case "automatic-speech-recognition":
      case "audio-classification":
      case "mask-generation":
      case "image-to-text":
      case "object-detection":
      case "depth-estimation":
      case "image-segmentation":
      case "image-classification":
      case "image-feature-extraction": {
        if (input?.startsWith("http")) {
          postBody["url"] = input;
        } else if (input?.startsWith("data")) {
          postBody["base64"] = input;
        }
      }
      //
      // multi-input
      case "question-answering": {
        postBody["context"] = input?.context;
        postBody["question"] = input?.question;
        break;
      }
      case "document-question-answering":
      case "visual-question-answering": {
        postBody["question"] = input?.question;
        postBody["url"] = input?.url;
        postBody["base64"] = input?.base64;
        break;
      }
      case "zero-shot-object-detection":
      case "zero-shot-image-classification": {
        postBody["candidate_labels"] = input?.candidate_labels;
        postBody["url"] = input?.url;
        postBody["base64"] = input?.base64;
        break;
      }
      case "zero-shot-classification": {
        postBody["candidate_labels"] = input?.candidate_labels;
        postBody["text"] = input?.text;
        break;
      }
      //
      // several task variants exist
      // so we cannot make assumptions on input, as it widely varies by model? so do nothing
      // does not require input
      case "unconditional-image-generation": {
        break;
      }
      default: {
        postBody["input"] = input;
      }
    }
    return this.#client.request(this.id, "POST", postBody, this.#providerKey);
  }
}

exports.Client = Client;
exports.Model = Model;
